{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Counter Application using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is an app for a simple word counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have developed the app to calculate the most common words\n",
    "# in the Complete Works of William Shakespeare from\n",
    "# Project Gutenberg. http://www.gutenberg.org/files/100/100-0.txt\n",
    "# This could be scaled to find the most common words on the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing Spark Context and spark session\n",
    "\n",
    "sc.stop()\n",
    "conf = SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a Resilient Distributed Dataset\n",
    "\n",
    "wordsList = ['cat', 'elephant', 'rat', 'cat', 'rat']\n",
    "wordsRDD = sc.parallelize(wordsList, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to pluralize each word \n",
    "\n",
    "def add_s_to_word(word):\n",
    "    return word + \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dogs', 'bats', 'bears', 'lions', 'bears', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "# Pass each item in the RDD into a map() transformation that applies \n",
    "# makePlural() function to each item\n",
    "\n",
    "pluralRDD = wordsRDD.map(add_s_to_word)\n",
    "print(pluralRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# Use map and lambda function to return\n",
    "# the number of occurences in each word. \n",
    "\n",
    "pluralLengths = (pluralRDD.map(lambda x: len(x))).collect()\n",
    "print(pluralLengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 1), ('elephant', 1), ('rat', 1), ('cat', 1), ('rat', 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new type of RDD called a pair RDD.\n",
    "# A Pair RDD is an RDD, where each element is a (k, v) pair where,\n",
    "# k is the key and v is the value\n",
    "\n",
    "# In this cell, we will emit (word, 1) pairs\n",
    "\n",
    "wordPairs = wordsRDD.map(lambda x : (x, 1))\n",
    "wordPairs.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: [1, 1]\n",
      "cat 2\n",
      "######\n",
      "elephant: [1]\n",
      "elephant 1\n",
      "######\n",
      "rat: [1, 1]\n",
      "rat 2\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "# Count with pair RDDs\n",
    "\n",
    "# Brute Force Approach -> collect() all of the elements and count\n",
    "# them in the driver program. But, that is really not effecient.\n",
    "\n",
    "\n",
    "# groupByKey() approach\n",
    "# Use groupByKey() to generate a pair RDD of type ('word', iterator)\n",
    "wordsGrouped = wordPairs.groupByKey()\n",
    "for key, value in wordsGrouped.collect():\n",
    "    print('{0}: {1}'.format(key, list(value)))\n",
    "    print(key, sum(value))\n",
    "    print('######')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduceByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 1), ('elephant', 1), ('rat', 1), ('cat', 1), ('rat', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cat', 2), ('elephant', 1), ('rat', 2)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(wordPairs.collect())\n",
    "wordCounts = wordPairs.reduceByKey(lambda x,y: x+y)\n",
    "wordCounts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
     ]
    }
   ],
   "source": [
    "wordCountsCollected = wordsRDD.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x+y)\n",
    "print(wordCountsCollected.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Finding unique words and a mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Find unique words in wordsRDD\n",
    "\n",
    "uniqueWords = wordsRDD.distinct().count()\n",
    "print(uniqueWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1.6666666666666667\n",
      "1.67\n"
     ]
    }
   ],
   "source": [
    "# Find the mean number of words per unique word in wordCounts.\n",
    "\n",
    "# Use a reduce() action to sum the counts in wordCounts \n",
    "# and then divide by the number of unique words\n",
    "from operator import add\n",
    "totalCount = (wordCounts.map(lambda x : x[1]).reduce(lambda x, y: x+y))\n",
    "average = totalCount/uniqueWords\n",
    "print(totalCount)\n",
    "print(average)\n",
    "print(round(average, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Apply word count to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[143] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "# Generate (word, count) pairs for all words in the file\n",
    "# Create a function which takes a RDD as an input\n",
    "# and returns <word, count> pairs\n",
    "\n",
    "def word_count(wordListRDD):\n",
    "    emitWords = wordListRDD.map(lambda x: (x, 1))\n",
    "    wordCountPairs = emitWords.reduceByKey(lambda x, y : x+ y)\n",
    "    return wordCountPairs\n",
    "\n",
    "\n",
    "wordList = ['dog', 'bat', 'bear', 'lion', 'bear', 'dog']\n",
    "wordsRDD = sc.parallelize(wordList)\n",
    "print(word_count(wordsRDD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitalization and Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sub in module re:\n",
      "\n",
      "sub(pattern, repl, string, count=0, flags=0)\n",
      "    Return the string obtained by replacing the leftmost\n",
      "    non-overlapping occurrences of the pattern in string by the\n",
      "    replacement repl.  repl can be either a string or a callable;\n",
      "    if a string, backslash escapes in it are processed.  If it is\n",
      "    a callable, it's passed the match object and must return\n",
      "    a replacement string to be used.\n",
      "\n",
      "ksdfybjksdh yyy ui\n",
      "hi you\n",
      "no underscore\n"
     ]
    }
   ],
   "source": [
    "# 1. Words should be counted independent of lower or upper case.\n",
    "# 2. Punctuations should not be considered.\n",
    "# 3. Any leading or trailing spaces should be removed.\n",
    "\n",
    "import re\n",
    "def removePunctuationWithoutRegex(line):\n",
    "    line = line.lower().strip()\n",
    "    words = []\n",
    "    temp = \"\"\n",
    "    for char in line:\n",
    "        if ' ' == char:\n",
    "            words.append(temp)\n",
    "            temp = \"\"\n",
    "            continue\n",
    "        if char.isdigit():\n",
    "            temp += char\n",
    "            continue\n",
    "        if char in 'abcdefghijklmnopqrstuvwxyz':\n",
    "            temp += char\n",
    "    if char != ' ':\n",
    "        words.append(temp)\n",
    "    return words\n",
    "\n",
    "\n",
    "def removePunctuation(string):\n",
    "    string = string.strip().lower()\n",
    "    string = re.sub(r'[^0-9a-zA-Z\\s]', '', string)\n",
    "    return string\n",
    "    \n",
    "\n",
    "help(re.sub)\n",
    "test_cases = [\" ksdfY'bjksdh, YY'Y uI      \", \"Hi, you!\", \"  No under_score!\"]\n",
    "for string in test_cases:\n",
    "    print(removePunctuation(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \n",
      "1: project gutenbergs the complete works of william shakespeare by william\n",
      "2: shakespeare\n",
      "3: \n",
      "4: this ebook is for the use of anyone anywhere in the united states and\n",
      "5: most other parts of the world at no cost and with almost no restrictions\n",
      "6: whatsoever  you may copy it give it away or reuse it under the terms\n",
      "7: of the project gutenberg license included with this ebook or online at\n",
      "8: wwwgutenbergorg  if you are not located in the united states youll\n",
      "9: have to check the laws of the country where you are located before using\n",
      "10: this ebook\n",
      "11: \n",
      "12: \n",
      "13: title the complete works of william shakespeare\n",
      "14: \n"
     ]
    }
   ],
   "source": [
    "# We will use \"Complete Works of William Shakespeare\" from \n",
    "# Project Gutenberg -> http://www.gutenberg.org/files/100/100-0.txt\n",
    "# We use SparkContext.textFile() to convert a text file into a RDD\n",
    "import os.path\n",
    "\n",
    "baseDir = os.getcwd()\n",
    "# inputDir = os.path.join('General', 'Spark', 'works_of_shakespeare.txt')\n",
    "# fileName = os.path.join(baseDir, inputDir)\n",
    "fileName = os.path.join(baseDir, 'works_of_shakespeare.txt')\n",
    "\n",
    "shakespeareRDD = sc.textFile(fileName, 8).map(removePunctuation)\n",
    "print('\\n'.join(shakespeareRDD\n",
    "               .zipWithIndex() # to (line, lineNum)\n",
    "               .map(lambda x: '{0}: {1}'.format(x[1], x[0])) # to 'lineNum: line'\n",
    "                .take(15)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Before we calculate wordCount, we need two address two issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First issue is that we need to split each line by its spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zwounds', 'zwounds', 'zwounds', 'zwounds', 'zwounds']\n",
      "1006999\n"
     ]
    }
   ],
   "source": [
    "shakespeareWordsRDD = shakespeareRDD.flatMap(lambda x: x.split(' '))\n",
    "shakespeareWordCount = shakespeareWordsRDD.count()\n",
    "print(shakespeareWordsRDD.top(5))\n",
    "print(shakespeareWordCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second issue is we need to remove empty lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960941\n"
     ]
    }
   ],
   "source": [
    "# This step involves removing all entries where the word is \"\"\n",
    "shakeWordsRDD = shakespeareWordsRDD.filter(lambda x: x!=\"\")\n",
    "shakeWordCount = shakeWordsRDD.count()\n",
    "print(shakeWordCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 30186\n",
      "and: 28388\n",
      "i: 21944\n",
      "to: 20912\n",
      "of: 18811\n",
      "a: 16150\n",
      "you: 14437\n",
      "my: 13182\n",
      "in: 12186\n",
      "that: 11778\n",
      "is: 9713\n",
      "not: 9066\n",
      "with: 8524\n",
      "me: 8263\n",
      "for: 8195\n"
     ]
    }
   ],
   "source": [
    "top15WordsAndCounts = word_count(shakeWordsRDD).takeOrdered(15, lambda x:-1*x[1])\n",
    "print('\\n'.join(map(lambda x: '{0}: {1}'.format(x[0], x[1]), top15WordsAndCounts)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
